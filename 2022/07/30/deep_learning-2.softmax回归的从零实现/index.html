

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon_yt.png">
  <link rel="icon" href="/img/favicon_yt.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Echo Yu">
  <meta name="keywords" content="ML">
  
    <meta name="description" content="softmax回归回归可以用于预测多少的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。 事实上，我们也对分类问题感兴趣：不是问“多少”，而是问“哪一个”：  某个电子邮件是否属于垃圾邮件文件夹？ 某个用户可能注册或不注册订阅服务？ 某个图像描绘的是驴、狗、猫、还是鸡？ 某人接下来最有可能看哪部电影？  通常，机器学习实践者用分类这个词来描述两个有微妙差别的问题：">
<meta property="og:type" content="article">
<meta property="og:title" content="deep_learning-2.softmax回归的从零实现">
<meta property="og:url" content="http://yuting0907.github.io/2022/07/30/deep_learning-2.softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0/index.html">
<meta property="og:site_name" content="YUTING">
<meta property="og:description" content="softmax回归回归可以用于预测多少的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。 事实上，我们也对分类问题感兴趣：不是问“多少”，而是问“哪一个”：  某个电子邮件是否属于垃圾邮件文件夹？ 某个用户可能注册或不注册订阅服务？ 某个图像描绘的是驴、狗、猫、还是鸡？ 某人接下来最有可能看哪部电影？  通常，机器学习实践者用分类这个词来描述两个有微妙差别的问题：">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-07-30T14:11:38.000Z">
<meta property="article:modified_time" content="2022-10-06T02:26:50.972Z">
<meta property="article:author" content="Echo Yu">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>deep_learning-2.softmax回归的从零实现 - YUTING</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/reward.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"yuting0907.github.io","root":"/","version":"1.9.0","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>EchoYu&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="deep_learning-2.softmax回归的从零实现"></span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        Echo Yu
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-07-30 22:11" pubdate>
          2022年7月30日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          71 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">deep_learning-2.softmax回归的从零实现</h1>
            
            <div class="markdown-body">
              
              <h2 id="softmax回归"><a href="#softmax回归" class="headerlink" title="softmax回归"></a>softmax回归</h2><p>回归可以用于预测<em>多少</em>的问题。 比如预测房屋被售出价格，或者棒球队可能获得的胜场数，又或者患者住院的天数。</p>
<p>事实上，我们也对<em>分类</em>问题感兴趣：不是问“多少”，而是问“哪一个”：</p>
<ul>
<li>某个电子邮件是否属于垃圾邮件文件夹？</li>
<li>某个用户可能<em>注册</em>或<em>不注册</em>订阅服务？</li>
<li>某个图像描绘的是驴、狗、猫、还是鸡？</li>
<li>某人接下来最有可能看哪部电影？</li>
</ul>
<p>通常，机器学习实践者用<em>分类</em>这个词来描述两个有微妙差别的问题： 1. 我们只对样本的“硬性”类别感兴趣，即属于哪个类别； 2. 我们希望得到“软性”类别，即得到属于每个类别的概率。 这两者的界限往往很模糊。其中的一个原因是：即使我们只关心硬类别，我们仍然使用软类别的模型。</p>
<h3 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h3><p>我们从一个图像分类问题开始。 假设每次输入是一个2×2的灰度图像。 我们可以用一个标量表示每个像素值，每个图像对应四个特征x1,x2,x3,x4。 此外，假设每个图像属于类别“猫”，“鸡”和“狗”中的一个。</p>
<p>接下来，我们要选择如何表示标签。 我们有两个明显的选择：最直接的想法是选择y∈{1,2,3}， 其中整数分别代表狗猫鸡{狗,猫,鸡}。 这是在计算机上存储此类信息的有效方法。 如果类别间有一些自然顺序， 比如说我们试图预测婴儿儿童青少年青年人中年人老年人{婴儿,儿童,青少年,青年人,中年人,老年人}， 那么将这个问题转变为回归问题，并且保留这种格式是有意义的。</p>
<p>但是一般的分类问题并不与类别之间的自然顺序有关。 幸运的是，统计学家很早以前就发明了一种表示分类数据的简单方法：<em>独热编码</em>（one-hot encoding）。 独热编码是一个向量，它的分量和类别一样多。 类别对应的分量设置为1，其他所有分量设置为0。 在我们的例子中，标签y将是一个三维向量， 其中(1,0,0)对应于“猫”、(0,1,0)对应于“鸡”、(0,0,1)对应于“狗”：</p>
<h3 id="softmax运算"><a href="#softmax运算" class="headerlink" title="softmax运算"></a>softmax运算</h3><p>现在我们将优化参数以最大化观测数据的概率。 为了得到预测结果，我们将设置一个阈值，如选择具有最大概率的标签。</p>
<p>我们希望模型的输出y^j可以视为属于类j的概率， 然后选择具有最大输出值的类别argmaxjyj作为我们的预测。 例如，如果y^1、y^2和y^3分别为0.1、0.8和0.1， 那么我们预测的类别是2，在我们的例子中代表“鸡”。</p>
<p>然而我们能否将未规范化的预测o直接视作我们感兴趣的输出呢？ 答案是否定的。 因为将线性层的输出直接视为概率时存在一些问题： 一方面，我们没有限制这些输出数字的总和为1。 另一方面，根据输入的不同，它们可以为负值。</p>
<p>要将输出视为概率，我们必须保证在任何数据上的输出都是非负的且总和为1。 此外，我们需要一个训练目标，来鼓励模型精准地估计概率。 在分类器输出0.5的所有样本中，我们希望这些样本有一半实际上属于预测的类。 这个属性叫做<em>校准</em>（calibration）。</p>
<h2 id="Softmax的从零开始实现"><a href="#Softmax的从零开始实现" class="headerlink" title="Softmax的从零开始实现"></a>Softmax的从零开始实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> IPython <span class="hljs-keyword">import</span> display<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br></code></pre></td></tr></table></figure>

<h3 id="1-初始化模型参数"><a href="#1-初始化模型参数" class="headerlink" title="1.初始化模型参数"></a>1.初始化模型参数</h3><p>和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。 原始数据集中的每个样本都是28×28的图像。 在本节中，我们将展平每个图像，把它们看作长度为784的向量。 在后面的章节中，我们将讨论能够利用图像空间结构的特征， 但现在我们暂时只把每个像素位置看作一个特征。</p>
<p>回想一下，在softmax回归中，我们的输出与类别一样多。 因为我们的数据集有10个类别，所以网络输出维度为10。 因此，权重将构成一个784×10的矩阵， 偏置将构成一个1×10的行向量。 与线性回归一样，我们将使用正态分布初始化我们的权重<code>W</code>，偏置初始化为0。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">num_inputs = <span class="hljs-number">784</span><br>num_outputs = <span class="hljs-number">10</span><br><br>W = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.zeros(num_outputs, requires_grad=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>



<h3 id="2-定义softmax操作"><a href="#2-定义softmax操作" class="headerlink" title="2.定义softmax操作"></a>2.定义softmax操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">X = torch.tensor([[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>]])<br>X.<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>, keepdim=<span class="hljs-literal">True</span>), X.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<p>回想一下，实现softmax由三个步骤组成：</p>
<ol>
<li>对每个项求幂（使用<code>exp</code>）；</li>
<li>对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；</li>
<li>将每一行除以其规范化常数，确保结果的和为1。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">X</span>):<br>    X_exp = torch.exp(X)<br>    partition = X_exp.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> X_exp / partition  <span class="hljs-comment"># 这里应用了广播机制</span><br>  <br>X = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">5</span>))<br>X_prob = softmax(X)<br>X_prob, X_prob.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>)<br><br>(tensor([[<span class="hljs-number">0.2290</span>, <span class="hljs-number">0.1027</span>, <span class="hljs-number">0.1771</span>, <span class="hljs-number">0.0187</span>, <span class="hljs-number">0.4725</span>],<br>         [<span class="hljs-number">0.0509</span>, <span class="hljs-number">0.2083</span>, <span class="hljs-number">0.6785</span>, <span class="hljs-number">0.0430</span>, <span class="hljs-number">0.0193</span>]]),<br> tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]))<br></code></pre></td></tr></table></figure>

<h3 id="3-定义模型"><a href="#3-定义模型" class="headerlink" title="3. 定义模型"></a>3. 定义模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">net</span>(<span class="hljs-params">X</span>):<br>    <span class="hljs-keyword">return</span> softmax(torch.matmul(X.reshape((-<span class="hljs-number">1</span>, W.shape[<span class="hljs-number">0</span>])), W) + b)<br></code></pre></td></tr></table></figure>

<h3 id="4-定义损失函数"><a href="#4-定义损失函数" class="headerlink" title="4.定义损失函数"></a>4.定义损失函数</h3><p>回顾一下，交叉熵采用真实标签的预测概率的负对数似然。 这里我们不使用Python的for循环迭代预测（这往往是低效的）， 而是通过一个运算符选择所有元素。 下面，我们创建一个数据样本<code>y_hat</code>，其中包含2个样本在3个类别的预测概率， 以及它们对应的标签<code>y</code>。 有了<code>y</code>，我们知道在第一个样本中，第一类是正确的预测； 而在第二个样本中，第三类是正确的预测。 然后使用<code>y</code>作为<code>y_hat</code>中概率的索引， 我们选择第一个样本中第一个类的概率和第二个样本中第三个类的概率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">y = torch.tensor([<span class="hljs-number">0</span>, <span class="hljs-number">2</span>])<br>y_hat = torch.tensor([[<span class="hljs-number">0.1</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>], [<span class="hljs-number">0.3</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.5</span>]])<br>y_hat[[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], y]<br><br>tensor([<span class="hljs-number">0.1000</span>, <span class="hljs-number">0.5000</span>])<br></code></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy</span>(<span class="hljs-params">y_hat, y</span>):<br>    <span class="hljs-keyword">return</span> - torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br><br>cross_entropy(y_hat, y)<br><br>tensor([<span class="hljs-number">2.3026</span>, <span class="hljs-number">0.6931</span>])<br></code></pre></td></tr></table></figure>



<h3 id="5-分类精度"><a href="#5-分类精度" class="headerlink" title="5.分类精度"></a>5.分类精度</h3><p>给定预测概率分布<code>y_hat</code>，当我们必须输出硬预测（hard prediction）时， 我们通常选择预测概率最高的类。 许多应用都要求我们做出选择。如Gmail必须将电子邮件分类为“Primary（主要邮件）”、 “Social（社交邮件）”、“Updates（更新邮件）”或“Forums（论坛邮件）”。 Gmail做分类时可能在内部估计概率，但最终它必须在类中选择一个。</p>
<p>当预测与标签分类<code>y</code>一致时，即是正确的。 分类精度即正确预测数量与总预测数量之比。 虽然直接优化精度可能很困难（因为精度的计算不可导）， 但精度通常是我们最关心的性能衡量标准，我们在训练分类器时几乎总会关注它。</p>
<p>为了计算精度，我们执行以下操作。 首先，如果<code>y_hat</code>是矩阵，那么假定第二个维度存储每个类的预测分数。 我们使用<code>argmax</code>获得每行中最大元素的索引来获得预测类别。 然后我们将预测类别与真实<code>y</code>元素进行比较。 由于等式运算符“<code>==</code>”对数据类型很敏感， 因此我们将<code>y_hat</code>的数据类型转换为与<code>y</code>的数据类型一致。 结果是一个包含0（错）和1（对）的张量。 最后，我们求和会得到正确预测的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">y_hat, y</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;计算预测正确的数量&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(y_hat.shape) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> y_hat.shape[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span>:<br>        y_hat = y_hat.argmax(axis=<span class="hljs-number">1</span>)<br>    cmp = y_hat.<span class="hljs-built_in">type</span>(y.dtype) == y<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(cmp.<span class="hljs-built_in">type</span>(y.dtype).<span class="hljs-built_in">sum</span>())<br></code></pre></td></tr></table></figure>

<p>我们将继续使用之前定义的变量<code>y_hat</code>和<code>y</code>分别作为预测的概率分布和标签。 可以看到，第一个样本的预测类别是2（该行的最大元素为0.6，索引为2），这与实际标签0不一致。 第二个样本的预测类别是2（该行的最大元素为0.5，索引为2），这与实际标签2一致。 因此，这两个样本的分类精度率为0.5。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">accuracy(y_hat, y) / <span class="hljs-built_in">len</span>(y)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">同样，对于任意数据迭代器data_iter可访问的数据集， 我们可以评估在任意模型net的精度。<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_accuracy</span>(<span class="hljs-params">net, data_iter</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;计算在指定数据集上模型的精度&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, torch.nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 将模型设置为评估模式</span><br>    metric = Accumulator(<span class="hljs-number">2</span>)  <span class="hljs-comment"># 正确预测数、预测总数</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            metric.add(accuracy(net(X), y), y.numel())<br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br></code></pre></td></tr></table></figure>



<p>这里定义一个实用程序类<code>Accumulator</code>，用于对多个变量进行累加。 在上面的<code>evaluate_accuracy</code>函数中， 我们在<code>Accumulator</code>实例中创建了2个变量， 分别用于存储正确预测的数量和预测的总数量。 当我们遍历数据集时，两者都将随着时间的推移而累加。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Accumulator</span>:  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;在n个变量上累加&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * n<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, *args</span>):<br>        self.data = [a + <span class="hljs-built_in">float</span>(b) <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.data, args)]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset</span>(<span class="hljs-params">self</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * <span class="hljs-built_in">len</span>(self.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> self.data[idx]<br></code></pre></td></tr></table></figure>



<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">evaluate<span class="hljs-constructor">_accuracy(<span class="hljs-params">net</span>, <span class="hljs-params">test_iter</span>)</span><br></code></pre></td></tr></table></figure>



<h3 id="6-训练"><a href="#6-训练" class="headerlink" title="6.训练"></a>6.训练</h3><p>首先，我们定义一个函数来训练一个迭代周期。 请注意，<code>updater</code>是更新模型参数的常用函数，它接受批量大小作为参数。 它可以是<code>d2l.sgd</code>函数，也可以是框架的内置优化函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_epoch_ch3</span>(<span class="hljs-params">net, train_iter, loss, updater</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;训练模型一个迭代周期（定义见第3章）&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 将模型设置为训练模式</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, torch.nn.Module):<br>        net.train()<br>    <span class="hljs-comment"># 训练损失总和、训练准确度总和、样本数</span><br>    metric = Accumulator(<span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-comment"># 计算梯度并更新参数</span><br>        y_hat = net(X)<br>        l = loss(y_hat, y)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(updater, torch.optim.Optimizer):<br>            <span class="hljs-comment"># 使用PyTorch内置的优化器和损失函数</span><br>            updater.zero_grad()<br>            l.mean().backward()<br>            updater.step()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 使用定制的优化器和损失函数</span><br>            l.<span class="hljs-built_in">sum</span>().backward()<br>            updater(X.shape[<span class="hljs-number">0</span>])<br>        metric.add(<span class="hljs-built_in">float</span>(l.<span class="hljs-built_in">sum</span>()), accuracy(y_hat, y), y.numel())<br>    <span class="hljs-comment"># 返回训练损失和训练精度</span><br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>], metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Animator</span>:  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;在动画中绘制数据&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, xlabel=<span class="hljs-literal">None</span>, ylabel=<span class="hljs-literal">None</span>, legend=<span class="hljs-literal">None</span>, xlim=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                 ylim=<span class="hljs-literal">None</span>, xscale=<span class="hljs-string">&#x27;linear&#x27;</span>, yscale=<span class="hljs-string">&#x27;linear&#x27;</span>,</span><br><span class="hljs-params">                 fmts=(<span class="hljs-params"><span class="hljs-string">&#x27;-&#x27;</span>, <span class="hljs-string">&#x27;m--&#x27;</span>, <span class="hljs-string">&#x27;g-.&#x27;</span>, <span class="hljs-string">&#x27;r:&#x27;</span></span>), nrows=<span class="hljs-number">1</span>, ncols=<span class="hljs-number">1</span>,</span><br><span class="hljs-params">                 figsize=(<span class="hljs-params"><span class="hljs-number">3.5</span>, <span class="hljs-number">2.5</span></span>)</span>):<br>        <span class="hljs-comment"># 增量地绘制多条线</span><br>        <span class="hljs-keyword">if</span> legend <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            legend = []<br>        d2l.use_svg_display()<br>        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)<br>        <span class="hljs-keyword">if</span> nrows * ncols == <span class="hljs-number">1</span>:<br>            self.axes = [self.axes, ]<br>        <span class="hljs-comment"># 使用lambda函数捕获参数</span><br>        self.config_axes = <span class="hljs-keyword">lambda</span>: d2l.set_axes(<br>            self.axes[<span class="hljs-number">0</span>], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)<br>        self.X, self.Y, self.fmts = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, fmts<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, x, y</span>):<br>        <span class="hljs-comment"># 向图表中添加多个数据点</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(y, <span class="hljs-string">&quot;__len__&quot;</span>):<br>            y = [y]<br>        n = <span class="hljs-built_in">len</span>(y)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(x, <span class="hljs-string">&quot;__len__&quot;</span>):<br>            x = [x] * n<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.X:<br>            self.X = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.Y:<br>            self.Y = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        <span class="hljs-keyword">for</span> i, (a, b) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(x, y)):<br>            <span class="hljs-keyword">if</span> a <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> b <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                self.X[i].append(a)<br>                self.Y[i].append(b)<br>        self.axes[<span class="hljs-number">0</span>].cla()<br>        <span class="hljs-keyword">for</span> x, y, fmt <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.X, self.Y, self.fmts):<br>            self.axes[<span class="hljs-number">0</span>].plot(x, y, fmt)<br>        self.config_axes()<br>        display.display(self.fig)<br>        display.clear_output(wait=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>



<p>接下来我们实现一个训练函数， 它会在<code>train_iter</code>访问到的训练数据集上训练一个模型<code>net</code>。 该训练函数将会运行多个迭代周期（由<code>num_epochs</code>指定）。 在每个迭代周期结束时，利用<code>test_iter</code>访问到的测试数据集对模型进行评估。 我们将利用<code>Animator</code>类来可视化训练进度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch3</span>(<span class="hljs-params">net, train_iter, test_iter, loss, num_epochs, updater</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;训练模型（定义见第3章）&quot;&quot;&quot;</span><br>    animator = Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs], ylim=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.9</span>],<br>                        legend=[<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)<br>        test_acc = evaluate_accuracy(net, test_iter)<br>        animator.add(epoch + <span class="hljs-number">1</span>, train_metrics + (test_acc,))<br>    train_loss, train_acc = train_metrics<br>    <span class="hljs-keyword">assert</span> train_loss &lt; <span class="hljs-number">0.5</span>, train_loss<br>    <span class="hljs-keyword">assert</span> train_acc &lt;= <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> train_acc &gt; <span class="hljs-number">0.7</span>, train_acc<br>    <span class="hljs-keyword">assert</span> test_acc &lt;= <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> test_acc &gt; <span class="hljs-number">0.7</span>, test_acc<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">lr = <span class="hljs-number">0.1</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">updater</span>(<span class="hljs-params">batch_size</span>):<br>    <span class="hljs-keyword">return</span> d2l.sgd([W, b], lr, batch_size)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">num_epochs = <span class="hljs-number">10</span><br>train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)<br></code></pre></td></tr></table></figure>



<h3 id="7-预测"><a href="#7-预测" class="headerlink" title="7.预测"></a>7.预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_ch3</span>(<span class="hljs-params">net, test_iter, n=<span class="hljs-number">6</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;预测标签（定义见第3章）&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>        <span class="hljs-keyword">break</span><br>    trues = d2l.get_fashion_mnist_labels(y)<br>    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>    titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>    d2l.show_images(<br>        X[<span class="hljs-number">0</span>:n].reshape((n, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br><br>predict_ch3(net, test_iter)<br></code></pre></td></tr></table></figure>





<h2 id="Softmax的简洁实现"><a href="#Softmax的简洁实现" class="headerlink" title="Softmax的简洁实现"></a>Softmax的简洁实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">############## 1. 初始化模型参数################</span><br><br><span class="hljs-comment"># PyTorch不会隐式地调整输入的形状。因此，</span><br><span class="hljs-comment"># 我们在线性层前定义了展平层（flatten），来调整网络输入的形状</span><br>net = nn.Sequential(nn.Flatten(), nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br><br>net.apply(init_weights);<br><br><span class="hljs-comment">############## 2. 重新审视Softmax的实现################</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br><br><span class="hljs-comment">############## 3. 优化算法 ###########################</span><br>trainer = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.1</span>)<br><br><span class="hljs-comment">############## 4. 训练 ##############################</span><br>num_epochs = <span class="hljs-number">10</span><br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure>



<h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><p>问题1: softmax回归和logistic回归分析是一样的吗？</p>
<p>softmax回归是多分类，logistic回归是2分类问题</p>
<p>问题2: batch_size设置为1或者设置为4，设置4是设置为1的4倍速度吗？</p>
<p>不是的，batch_size的大小与否，它的计算量都是不会发生变化的，发生变化的是计算的并行度是不是能增加使得整个执行的效率能不能增加</p>
<p>问题3: 在计算精度的时候，为什么需要使用new.eval()将模型设置成评估模式？</p>
<p>设置eval模式是为了不算梯度，默认是会算梯度的，可以不用开，但在性能上可能会好一点。</p>
<p>问题4: 如何把自己的图片数据集用于训练？</p>
<p>pytorch官方文档可以去看一下，是支持本地照片用训练集的</p>
<p>参考：<a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/">https://zh-v2.d2l.ai</a></p>

              
            </div>
            <hr/>
            
            <!-- donate -->
            <div class="reward-container">
            	
            		<button id="rewardBtn" class="reward-btn">
            			 
            				  Donate
            				
            		</button>
            		<p class="tea">觉得不错的话，给点打赏吧 ୧(๑•̀⌄•́๑)૭</p>
            		<div id="rewardImgContainer" class="reward-img-container">
                     	<div class="singleImgContainer">
                        	<img id="wechatImg" class="reward-img" src="/img/wechatpay.jpg" srcset="/img/loading.gif" lazyload alt="">
                            <p class="wechatPay">wechat pay</p>
                      </div>
                      <div class="singleImgContainer">
                           	<img id="alipayImg" class="reward-img" src="/img/alipay.jpg" srcset="/img/loading.gif" lazyload alt="">
                            <p class="aliPay">alipay</p>
                      </div>
            		</div>
            	
            </div>
            
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Deep-Learning/" class="category-chain-item">Deep Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Deep-Learning/">#Deep Learning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>deep_learning-2.softmax回归的从零实现</div>
      <div>http://yuting0907.github.io/2022/07/30/deep_learning-2.softmax回归的从零实现/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Echo Yu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年7月30日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/07/31/deep-learning-3-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0/" title="deep_learning_3.多层感知机的从零实现">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">deep_learning_3.多层感知机的从零实现</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/07/27/PyTorch%E6%A1%86%E6%9E%B6-TensorDataset/" title="PyTorch框架-TensorDataset">
                        <span class="hidden-mobile">PyTorch框架-TensorDataset</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.4.16/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"KPXIfOuMVwWIv2Skprm5gYB4-gzGzoHsz","appKey":"f92SiTdYRrLO0zwfdQnRyXW1","path":"window.location.pathname","placeholder":"Just go go","avatar":"mm","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false,"enable":true,"appid":"KPXIfOuMVwWIv2Skprm5gYB4-gzGzoHsz","appkey":"f92SiTdYRrLO0zwfdQnRyXW1","verify":false,"notify":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>






  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            load: ['ui/lazy']
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.0/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/js/reward.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>

<!--  -->
<script type="text/javascript" src="/js/love.js"></script>

<!--动态线条背景-->
<script type="text/javascript"
color="220,220,220" opacity='0.7' zIndex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js">
</script>  

<!--浏览器搞笑标题-->
<script type="text/javascript" src="/js/FunnyTitle.js"></script>
